{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#membuat fungsi klasifier\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.metrics import f1_score,confusion_matrix\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "\r\n",
    "\r\n",
    "def classify_sentiment(classifier,chi_train_corpus_tf_idf,chi_test_corpus_tf_idf,label_train,label_test):\r\n",
    "    clf   = classifier\r\n",
    "    clf.fit(chi_train_corpus_tf_idf,label_train)\r\n",
    "    pred = clf.predict(chi_test_corpus_tf_idf)\r\n",
    "    accuracy = clf.score(chi_test_corpus_tf_idf,label_test)\r\n",
    "    cm = confusion_matrix(pred,label_test)\r\n",
    "    f1 = f1_score(pred,label_test)\r\n",
    "    return accuracy,f1,cm, pred, label_test\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def classifier_train(chi_train_corpus_tf_idf,label_train,chi_test_corpus_tf_idf,label_test,train_choice,test_choice):\r\n",
    "\r\n",
    "    rbf_parameters = [[0.9],[0.9],[0.9],[0.9],[0.9],[0.8],[0.9],[0.9],[0.8],[0.9],[0.9],[0.9]]\r\n",
    "\r\n",
    "    val = (train_choice)*3 + test_choice\r\n",
    "\r\n",
    "    Gamma = rbf_parameters[val][0]\r\n",
    "\r\n",
    "    classifiers = [MultinomialNB()]\r\n",
    "\r\n",
    "    \r\n",
    "    accu = []\r\n",
    "    \r\n",
    "    classify = [\"Multinomial NB\"]\r\n",
    "\r\n",
    "    for i in range(len(classifiers)):\r\n",
    "        acc,f1,cm, pred, label_test = classify_sentiment(classifiers[i],chi_train_corpus_tf_idf,chi_test_corpus_tf_idf,label_train,label_test)\r\n",
    "\r\n",
    "        accu.append(acc)\r\n",
    "\r\n",
    "        print(classify[i]+\" \"+\"F1 score adalah :\",f1)\r\n",
    "        print(classify[i]+\" \"+\"Classification Report:\")\r\n",
    "        print(classification_report(label_test, pred))\r\n",
    "        print(\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#membuat Fungsi ekstrak text menggunakan TF-IDF\r\n",
    "\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "\r\n",
    "vector_parameters = [[2,0.8],[3,0.8],[3,0.8],[3,0.8],[3,0.8],[3,0.8],[3,0.8],[3,0.8],[3,0.8],\r\n",
    "[3,0.8],[3,0.8],[3,0.8]]\r\n",
    "\r\n",
    "\r\n",
    "def featureextraction(train_corpus,test_corpus,label_train,train_choice,test_choice):\r\n",
    "\r\n",
    "\tval = (train_choice)*3 + test_choice\r\n",
    "\r\n",
    "\tparam  = vector_parameters[val]\r\n",
    "\tmindf = param[0]\r\n",
    "\tmaxdf = param[1]\r\n",
    "\r\n",
    "\tvectorizer = TfidfVectorizer(min_df=mindf,max_df=maxdf,use_idf=True,sublinear_tf=True,stop_words='english')\r\n",
    "\r\n",
    "\ttrain_corpus_tf_idf = vectorizer.fit_transform(train_corpus,label_train)\r\n",
    "\r\n",
    "\ttest_corpus_tf_idf = vectorizer.transform(test_corpus)\r\n",
    "\r\n",
    "\treturn [train_corpus_tf_idf,test_corpus_tf_idf]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#membuat Fungsi seleksi text menggunakan Chi-Square\r\n",
    "from sklearn.feature_selection import SelectKBest,chi2\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "chi_square_parameters = [[5000],[4000],[4000],[4000],[4000],[4000],[4000],['all'],['all'],['all'],\r\n",
    "['all'],['all'],[2500],['all']]\r\n",
    "\r\n",
    "\r\n",
    "def featureselection(train_corpus_tf_idf,test_corpus_tf_idf,label_train,train_choice,test_choice):\r\n",
    "\r\n",
    "\tval = (train_choice)*3 + test_choice\r\n",
    "\r\n",
    "\tk = chi_square_parameters[val][0]\r\n",
    "\r\n",
    "\tif(k=='all'):\r\n",
    "\t\tK = train_corpus_tf_idf.shape[1]\r\n",
    "\telse:\r\n",
    "\t\tK = k \r\n",
    "\r\n",
    "\tvectorizer_chi2 = SelectKBest(chi2,k=K)\r\n",
    "\r\n",
    "\tchi_train_corpus_tf_idf = vectorizer_chi2.fit_transform(train_corpus_tf_idf,label_train)\r\n",
    "\r\n",
    "\tchi_test_corpus_tf_idf = vectorizer_chi2.transform(test_corpus_tf_idf)\r\n",
    "\r\n",
    "\treturn [chi_train_corpus_tf_idf,chi_test_corpus_tf_idf]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#membuat Fungsi preprocess & train data\r\n",
    "import re\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from nltk.corpus import stopwords\r\n",
    "\r\n",
    "\r\n",
    "train_list = [\"Dataset/Actualdata/Books/Bookstrain.txt\",\"Dataset/Actualdata/Dvd/Dvdtrain.txt\",\"Dataset/Actualdata/Electronics/Electronicstrain.txt\",\"Dataset/Actualdata/Kitchen/Kitchentrain.txt\"]\r\n",
    "\r\n",
    "test_list = [\"Dataset/Actualdata/Books/Bookstest.txt\",\"Dataset/Actualdata/Dvd/Dvdtest.txt\",\"Dataset/Actualdata/Electronics/Electronicstest.txt\",\"Dataset/Actualdata/Kitchen/Kitchentest.txt\"]\r\n",
    "\r\n",
    "\r\n",
    "stopword = stopwords.words('english') \r\n",
    "\r\n",
    "def preprocess(sentence):\r\n",
    "\tsentence = re.sub('[^\\w\\s]',\" \",str(sentence))\r\n",
    "\tsentence = re.sub('[^a-zA-Z]',\" \",str(sentence))\r\n",
    "\tsents = word_tokenize(sentence)\r\n",
    "\tnew_sents = \" \"\r\n",
    "\tfor i in range(len(sents)):\r\n",
    "\t\tif(sents[i].lower() not in stopword):\r\n",
    "\t\t\tnew_sents+=sents[i].lower()+\" \"\r\n",
    "\treturn new_sents\r\n",
    "\r\n",
    "def preprocess_test(choice):\r\n",
    "\r\n",
    "\tthe_file = test_list[choice]\r\n",
    "\t#print(the_file)\r\n",
    "\twith open(the_file,'r',encoding='utf-8') as f:\r\n",
    "\t\ttest_data = f.readlines()\r\n",
    "\r\n",
    "\tcorpus_test = []\r\n",
    "\r\n",
    "\tfor i in range(400):\r\n",
    "\t\tsent = test_data[i]\r\n",
    "\t\tsent = sent[0:len(sent)-1]\r\n",
    "\t\tcorpus_test.append(preprocess(sent))\r\n",
    "\r\n",
    "\t#print(corpus_test[0])\r\n",
    "\r\n",
    "\tlabel_test = np.zeros(400)\r\n",
    "\tlabel_test[0:200] = 1\r\n",
    "\r\n",
    "\r\n",
    "\treturn [corpus_test,label_test]\r\n",
    "\r\n",
    "\r\n",
    "def preprocess_train(choice):\r\n",
    "\r\n",
    "\r\n",
    "\tthe_file = train_list[choice]\r\n",
    "\t#print(the_file)\r\n",
    "\twith open(the_file,'r',encoding='utf-8') as f:\r\n",
    "\t\ttrain_data = f.readlines()\r\n",
    "\r\n",
    "\r\n",
    "\tcorpus_train = []\r\n",
    "\r\n",
    "\tfor i in range(1600):\r\n",
    "\t\tsent = train_data[i]\r\n",
    "\t\tsent = sent[0:len(sent)-1]\r\n",
    "\t\tcorpus_train.append(preprocess(sent))\r\n",
    "\r\n",
    "\t#print(corpus_train[0])\r\n",
    "\r\n",
    "\tlabel_train = np.zeros(1600)\r\n",
    "\tlabel_train[0:800] = 1\r\n",
    "\r\n",
    "\treturn [corpus_train,label_train]\r\n",
    "\r\n",
    "def preprocessing(train_choice,test_choice):\r\n",
    "\r\n",
    "\tcorpus_train,label_train = preprocess_train(train_choice)\r\n",
    "\r\n",
    "\tcorpus_test,label_test = preprocess_test(test_choice)\r\n",
    "\r\n",
    "\treturn corpus_train,label_train,corpus_test,label_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#ada 4 data yang bisa di test yaitu books,dvd,electronics,kitchen\r\n",
    "#0 untuk books,1 untuk dvd,2 untuk electronics,3 untuk kitchen\r\n",
    "train = 1\r\n",
    "\r\n",
    "test = 2\r\n",
    "\r\n",
    "\t\r\n",
    "train_choice,test_choice = train,test\r\n",
    "\r\n",
    "pre_choice_train = train\r\n",
    "pre_choice_test = test\r\n",
    "\r\n",
    "corpus_train,label_train,corpus_test,label_test = preprocessing(pre_choice_train,pre_choice_test)\r\n",
    "\r\n",
    "\t\r\n",
    "train_corpus_tf_idf,test_corpus_tf_idf = featureextraction(corpus_train,corpus_test,label_train,train_choice,test_choice)\r\n",
    "\r\n",
    "chi_train_corpus_tf_idf,chi_test_corpus_tf_idf = featureselection(train_corpus_tf_idf,test_corpus_tf_idf,label_train,train_choice,test_choice)\r\n",
    "\r\n",
    "classifier_train(chi_train_corpus_tf_idf,label_train,chi_test_corpus_tf_idf,label_test,train_choice,test_choice)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Multinomial NB F1 score adalah : 0.6551724137931034\n",
      "Multinomial NB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.83      0.73       200\n",
      "         1.0       0.77      0.57      0.66       200\n",
      "\n",
      "    accuracy                           0.70       400\n",
      "   macro avg       0.71      0.70      0.69       400\n",
      "weighted avg       0.71      0.70      0.69       400\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "0edbecc9b6cb096fad560000fba39be3e8c326b164b418d7c8f8037b697b209d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}